# Optima-Partners

This repository is for the Optima Partners engineering assignments assessment. Specifically, the repositary is for the data engineering assessment.
<https://github.com/optima-partners/engineering-recruitment-assignments/blob/main/data-engineering/datapipeline/>

## Project layout

- `source-data/`   : Raw CSV inputs used by the analysis. Key files:
  - `races.csv` — high-level data for each race including date and time. Requirements are to combine date and time as one utc field, where null, time can be set as 00:00:00
  - `results.csv` — finishing position of each driver per race including fastest lap.
- `results/`       : Generated outputs (JSON files) by year, e.g. `stats_2018.json` through `stats_2024.json`.
- `solution/`      : Containing the primary scripting for the process,
  - `main.py` — script to import the CSVs and join based on `raceId`. Filters results to include only race winners (position = 1) and creates one JSON file per year with race statistics.
  - `functions.py` :
    — `import_csv_to_df()` function for importing CSV files to pandas DataFrames with configurable delimiters and index columns.
    - `publish_df_to_aws_bucket_as_json()` function for pushing JSON files to S3 bucket instead of/as well as outputting them to results/. **Configuration still required before this can be used. Execution code is currently commented out in main.py**

## Quick Start

### Prerequisites

- Python 3.13.9 or higher
- pandas library
- boto3 library (only when progressing to pushing to AWS bucket)
- Git

### Installation and Setup

1. **Clone the repository**

   ```bash
   git clone https://github.com/ijward/Optima-Partners.git
   cd Optima-Partners
   ```

2. **Install dependencies**

   ```bash
   pip install pandas
   ```

3. **Run the data pipeline**

   From the project root directory, execute:

   ```bash
   python3 solution/main.py
   ```

   Or, if using Windows:

   ```bash
   python solution/main.py
   ```

### Expected Output

When successful, the script will:

- Read CSV files from `source-data/` directory:
  - `races.csv` — race metadata with dates and times
  - `results.csv` — driver finishing positions and lap data
- Combine date and time fields into a single UTC datetime field (using "00:00:00" for null times)
- Filter results to include only race winners (position = 1)
- Join the datasets based on `raceId`
- Generate JSON output files in `results/` directory, organized by year:
  - `stats_2018.json` through `stats_2024.json`

Each output JSON file contains the following fields for that year's races:

- `year` — the race year
- `Race Name` — the name of the race
- `Race Round` — the round number in the season
- `Race Datetime` — the combined UTC datetime of the race
- `Race Winning driverId` — the driver ID of the race winner
- `Race Fastest Lap` — the fastest lap time recorded in the race

**NB: Testing has confirmed that not all races have a position 1 entry in the results dataset. The join has been set as 'Inner' so these races will not be output to JSON. Requirements need to be clarified and if necessary, join should be updated to 'Left' and retested.**

### Troubleshooting

- **ModuleNotFoundError: No module named 'pandas'**: Install pandas using `pip install pandas`
- **FileNotFoundError**: Ensure you're running the script from the project root directory
- **Permission denied**: On macOS/Linux, you may need to use `python3` instead of `python`

## Testing

The project includes comprehensive unit tests and quality checks:

### Running Tests

Execute all tests with coverage reporting:

```bash
pytest --cov --cov-report=html:testcov
```

### Test Coverage

- **test_process.py**: Core functionality tests
  - `test_import_csv_to_df_no_index()` — validates CSV import without index
  - `test_import_csv_to_df_no_delimiter()` — validates default delimiter handling
  - `test_import_csv_to_df_with_index_in_races()` — validates index setting for races data
  - `test_import_csv_to_df_with_index_in_results()` — validates index setting for results data
  - `test_csv_to_def_file_path_has_leading_trailing_slashes()` — handles path normalization
  - `test_import_csv_to_df_missing_file_raises()` — validates error handling for missing files
  - `test_import_csv_to_df_index_col_missing_raises()` — validates error handling for invalid index columns
  - `test_each_race_has_position_one_winner()` — validates race-winner relationships

### Coverage Report

HTML coverage reports are generated in `testcov/` directory. Open `testVcov/index.html` in a browser to view detailed coverage metrics.
